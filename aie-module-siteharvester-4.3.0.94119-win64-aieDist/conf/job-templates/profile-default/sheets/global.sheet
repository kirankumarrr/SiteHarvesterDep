#################################################################################################
# WARNING: Do NOT edit this file.  Doing so will cause incorrect crawl behavior in Site Harvester
#################################################################################################

#######
# base root map
#######
root=map, java.lang.Object

#######
# Provide metadata to the crawler
#######
root:metadata=primary, com.attivio.siteharvester.crawler.heritrix.writer.AttivioMetadataProvider

#######
# The robots honoring policy
#######
root:metadata:robots-honoring-policy=primary, com.attivio.siteharvester.crawler.heritrix.framework.AttivioRobotsHonoringPolicy
root:metadata:robots-honoring-policy:user-agents=list, java.lang.String

#######
# The logger module
#######
root:loggerModule=primary, org.archive.crawler.framework.CrawlerLoggerModule

#######
# Handling of seeds file
#######
root:seeds=primary, org.archive.modules.seeds.SeedModuleImpl

#######
# Scope rules to determine if a URL should be crawled
#######
# Main list of all following decide rules to iterate over and accept if anyone accepts
root:scope=object, com.attivio.siteharvester.crawler.heritrix.deciderules.AttivioDecideRuleSequence
root:scope:rules=list, org.archive.modules.deciderules.DecideRule
# Reject every url initially 
root:scope:rules:0=object, org.archive.modules.deciderules.RejectDecideRule
# Accept if passes Attivio scanner include rules and not exclude rules
root:scope:rules:1=object, com.attivio.siteharvester.crawler.heritrix.deciderules.AttivioDecideRule
# Reject paths with more than X repeating segments like http:/a/b/c/c/c/...
root:scope:rules:2=object, com.attivio.siteharvester.crawler.heritrix.deciderules.RepeatingPathDecideRule
# Reject paths with more than X segments
root:scope:rules:3=object, com.attivio.siteharvester.crawler.heritrix.deciderules.MaxPathSegmentsDecideRule
# Accept all pre-requisite (like robots.txt) urls
root:scope:rules:4=object, org.archive.modules.deciderules.PrerequisiteAcceptDecideRule

#######
# URI unique id
#######
root:uriUniqFilter=primary, org.archive.crawler.util.FPUriUniqFilter
root:uriUniqFilter:long-fp-set=primary, org.archive.util.fingerprint.MemLongFPSet

#######
# Queue assignment policy for queing and crawling URLs
#######
root:queue-assignment-policy=primary, com.attivio.siteharvester.crawler.heritrix.framework.ParallelSurtAuthorityQueueAssignmentPolicy

#######
# Server cache
#######
root:server-cache=primary, org.archive.modules.fetcher.DefaultServerCache

#######
# Credential store - no/op because we do form/basic auth now in AttivioFetchHttp
#######
root:credential-store=primary, com.attivio.siteharvester.crawler.heritrix.auth.AttivioCredentialStore

#######
# Crawl controller
#######
# main controller and frontier
root:controller=primary, com.attivio.siteharvester.crawler.heritrix.framework.AttivioCrawlController
root:controller:frontier=primary, com.attivio.siteharvester.crawler.heritrix.framework.AttivioMemoryFrontier
root:controller:frontier:queue-assignment-policy=object, com.attivio.siteharvester.crawler.heritrix.framework.ParallelSurtAuthorityQueueAssignmentPolicy
root:controller:frontier:delay-factor=float, 0.0
root:controller:frontier:max-retries=int, 3
root:controller:frontier:retry-delay-seconds=long, 10

#######
# rules to canonicalize the URLs
#######
root:controller:frontier:rules=list, org.archive.modules.canonicalize.CanonicalizationRule
# lowercase the URL
root:controller:frontier:rules:0=object, org.archive.modules.canonicalize.LowercaseRule
# strip user info
root:controller:frontier:rules:1=object, org.archive.modules.canonicalize.StripUserinfoRule
# strip number from www, like http://www[0-9]/... 
root:controller:frontier:rules:2=object, org.archive.modules.canonicalize.StripWWWNRule
# strip session ids
root:controller:frontier:rules:3=object, org.archive.modules.canonicalize.StripSessionIDs
# strip cold fusion session ids
root:controller:frontier:rules:4=object, org.archive.modules.canonicalize.StripSessionCFIDs
# strip trailing question marks and ampersands
root:controller:frontier:rules:5=object, org.archive.modules.canonicalize.FixupQueryStr
# does attivio connector supplied link canonicalization
root:controller:frontier:rules:6=object, com.attivio.siteharvester.crawler.heritrix.canonicalize.LinkCanonicalization
root:controller:frontier:scope=reference, root:scope

#######
# Processing rules for a crawled URL
#######
root:controller:processors=map, org.archive.modules.Processor
# decide if a URL is "in scope"
root:controller:processors:Preselector=object, org.archive.crawler.prefetch.Preselector
root:controller:processors:Preselector:scope=reference, root:scope
# ensures preconditions for a fetch are already done
root:controller:processors:Preprocessor=object, com.attivio.siteharvester.crawler.heritrix.processor.AttivioPreconditionEnforcer
# dns name resolution
root:controller:processors:DNS=object, com.attivio.siteharvester.crawler.heritrix.processor.AttivioFetchDNS
# get previous crawl info from crawl store
root:controller:processors:GetUniqueCrawlDocumentId=object, com.attivio.siteharvester.crawler.heritrix.processor.crawlerstore.DetermineUniqueCrawlDocumentId
# get previous crawl info from crawl store
root:controller:processors:GetPreviousCrawlInfo=object, com.attivio.siteharvester.crawler.heritrix.processor.crawlerstore.GetPreviousCrawlInfo
# fetch the content from the server and do authentication if required
root:controller:processors:HTTP=object, com.attivio.siteharvester.crawler.heritrix.framework.AttivioFetchHttp
root:controller:processors:HTTP:accept-headers=list, java.lang.String
root:controller:processors:HTTP:midfetch-rules=object, org.archive.modules.deciderules.DecideRuleSequence
# get more URLs to crawl from response headers
root:controller:processors:ExtractorHTTP=object, org.archive.modules.extractor.ExtractorHTTP
# get more URLs to crawl from body using regex as well as our anchor text and encoding parsing.  Also do canonical link handling
root:controller:processors:ExtractorHTML=object, com.attivio.siteharvester.crawler.heritrix.processor.AttivioExtractorHTML
# process and queue sitemaps files referenced in robots.txt
root:controller:processors:RobotsSiteMapsProcessor=object, com.attivio.siteharvester.crawler.heritrix.processor.RobotsSiteMapsProcessor
# get more URLs to crawl based on sitemaps content
root:controller:processors:SiteMapsProcessor=object, com.attivio.siteharvester.crawler.heritrix.processor.SiteMapsProcessor
# get more URLs to crawl from CSS
root:controller:processors:ExtractorCSS=object, org.archive.modules.extractor.ExtractorCSS
# get more URLs to crawl from Javascript
root:controller:processors:ExtractorJS=object, org.archive.modules.extractor.ExtractorJS
# get more URLs to crawl from flash/shockwave
root:controller:processors:ExtractorSWF=object, org.archive.modules.extractor.ExtractorSWF
# persist redirects in the crawler store
root:controller:processors:RedirectHandler=object, com.attivio.siteharvester.crawler.heritrix.processor.AttivioRedirectProcessor
# Persist crawled content
root:controller:processors:Archiver=object, com.attivio.siteharvester.crawler.heritrix.writer.AttivioWriterProcessor
# URL per-host info updated during fetch
root:controller:processors:Updater=object, org.archive.crawler.postprocessor.CrawlStateUpdater
# Determine which links are within scope
root:controller:processors:LinksScoper=object, com.attivio.siteharvester.crawler.heritrix.processor.AttivioLinksScoper
root:controller:processors:LinksScoper:scope=reference, root:scope
# Clean out unneeded info from the processor URI
root:controller:processors:ProcessorUriCleanup=object, com.attivio.siteharvester.crawler.heritrix.processor.AttivioUriCleanupProcessor
# schedule links found in previous processor stages for future crawl
root:controller:processors:Scheduler=object, org.archive.crawler.postprocessor.FrontierScheduler

#######
# Statistics tracking
#######
root:controller:statistics-tracker=object, org.archive.crawler.framework.StatisticsTrackerImpl
